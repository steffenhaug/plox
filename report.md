---
title: Graphics of mathematical communication
author: Steffen Haug
colorlinks: true
links-as-notes: true
header-includes:
- \usepackage{mathtools}
- \usepackage{xcolor}
- \usepackage{xfrac}
- \usepackage{csquotes}
- \interfootnotelinepenalty=10000
classoption:
- twocolumn
---
# Introduction
I am a big lover of math, and have used `matplotlib` and `MATLAB` a lot in the past,
both as part of studies and as part of work.
I also enjoy consuming content from math communicators online, such as
[Freya Holmér](https://www.youtube.com/c/Acegikmo),
[Mathologer](https://www.youtube.com/c/Mathologer), and perhaps the most famous,
[3Blue1Brown](https://www.youtube.com/c/3blue1brown).
They prove that you can entertain and educate a wide audience in mathematics,
provided the communication is visually appealing and interesting.
If you want to make _beautiful_ plots, `matplotlib` and `MATLAB` does not make it easy.
It is possible to shoehorn these tools into doing what you want if you know what to tweak,
as is demonstrated in
[this old notebook of mine](https://github.com/steffenhaug/nm/blob/master/int/rk3d.ipynb),
generating the following figure.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.625\columnwidth]{report/sphere_example.png}
\end{center}
\caption{Plot on a spherical surface generated by \texttt{matplotlib}}
\end{figure}

But this requires something like _150 lines of code_, tweaking settings, fiddling with
different parameters, and manually disabling or making transparent everything irrelevant.
In a similar vein, it is important to be able to make the plotting tools match the visuals
of \LaTeX\ both in terms of fonts, but also in terms of typesetting, because if you need
to put an integral on a figure it _has to look the same_ as the same integral
typeset in text next to the figure (at least if you are as pedantic as me).
Again, it is technically _possible_ to make `matplotlib` do this by changing the backend to
use Ti\textit{k}Z, and while this works brilliantly for document preparation,
generating your plot as plain text commands for \LaTeX\ makes animating anything for a digital- 
or interavtive presentation absolutely hopeless.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.625\columnwidth]{report/tex_labels_example.png}
\end{center}
\caption{Typesetting in a figures legend, generated by \texttt{matplotlib}.
Note that the legend has a font that matches the document it was embedded in
(not this document).}
\end{figure}

\begin{figure*}
\begin{center}
\includegraphics[width=0.625\textwidth]{report/sample.png}
\end{center}
\caption{Samples of some of the primitives the tool can render.
Note in particular the gradients; it demonstrates that all primitives
have texture-coordinates that can be used with customized fragment shading.}
\end{figure*}

So I want to make a tool that enables producing _high quality_ animated and interactive
mathematical visualizations.
The crux of this is that such visualizations can be _highly dynamic_.
The visual effects that could be applied to any geometrical primitive is limited only
by the users creativity.
To maintain _high quality_, primitives need to look _correct_ in all cases.
This includes arbitrary zoom, sheer transforms, and so on.
Anti-aliasing needs to look _good_, and be correct at all zoom levels.
It is NOT okay for text edges to become blurry as we zoom in,
or anything like that.
The styling of the primitives should be _very customizable_.
Technicalities should never limit creative expression -- any desired visual
effect should be achievable.

Especially text rasterization, as an instance of rasterization of _implicit geometry_,
is quite complex to do efficiently on a GPU, and this system went through quite a lot 
of iteration. This process, and other details, is outlined in depth in a separate
document -- a diary I wrote daily as I worked on the project.
The diary is quite unstructured, but it contains details about everything that did
not end up making it in to the project, and details about the process of discovery.
This report contains a brief summary of everything that _did_ make it, with rationale
and the bare minimal needed deetail.

Text rasterization is what ended up being the bulk of the work,
and this report will focus on the trade-off between the two best approaches i could find,
and modifications i made to suit the goals of the project.

A last point worth mentioning briefly is performance.
The goals of the project is first and foremost _correctness above all_, at the
cost of performance if necessary, but not to any extent.
In order to make _good_ interactive visualizations, it should at the very least
be capable of rendering at the native resolution and
at the native framerate, for example, 144Hz and $2560 \times 1440$ resolution
on modern hardware,
and _at the very least_ 60Hz and $1920 \times 1080$ resolution -- the current
"default choice" for higher-quality YouTube videos -- on virtually any sensible 
hardware including recent integrated graphics chips.

Graphical artifacts and any visual weirdness is considered bugs.

# Project structure & Demos
The project is implemented in Rust, and structured in two crates in a Cargo
workspace. The demo can be built by running `cargo build --release` from the
workspace root, or from the root of the binary crate `plox-example`, and executed with
`cargo run --release`, just like any normal Cargo project.

The library crate, `plox`, provides structures for graphical primitives like
text, circles, lines, linear splines and Bézier curves, and algorithms for
tesselating and rasterizing them. It also provides a _very simplistic_ (and
unsafe) abstraction of OpenGL based loosely on `gloom` from last year.
The library crate makes no choices about how you should obtain an OpenGL context,
the only requirement is that the `gl` crate is initialized with your context
so the driver function pointers are loaded.
It also makes no assumptions about how the user might want to store or process
the provided primitives.
All primitives allows submitting a customized shader when rasterizing, in place 
of the default one for the primitive.
These choices are made to provide flexibility.
Said shader needs to conform to the same interface as the default shaders to work
correctly (i. e. define the necessary uniforms and process the same vertex array format),
so some knowledge of internals is needed, but you can easily create your own shader
copying and modifying the default shaders.

The binary crate, `plox-example`, uses `glutin` to get an OpenGL context, similar to
`gloom`, but i re-wrote the core of the application to redraw using the 
`RedrawRequested`-event synchronously in the event loop,
because this makes it easy to redraw lazily in response to state changes.
Since this is not a "real-time 3D application", constant 60FPS is not really needed
or desirable, it is just wasting precious processing power.

The demo project uses a super simple entity component system to manage the `plox`-primitives.
This data-driven design is relatively efficient, and very easy to implement
in Rust: The "components" are just a big bundle of data packed into a `struct`, and the
"systems" are just functions that process said data.
The `plox` rasterization and tesselation algorithms are accessed from the rendering-,
animation- and tesselation- systems in `plox-example`.
The demo itself is just displaying various graphics primitives with some super
simple animation, but in its construction it also demonstrates how to embed `plox`
in applications that need to draw graphics.

The name is a combination of the words "plot" and "oxide" because every
Rust projects apparently needs to have a silly name.

# Text rasterization
Computer fonts are designed as splines of Bézier curves.
This is useful for designers, because Bézier curves can produce very beautiful
curves, while being simple for programmers to represent using a few control points.
A Bézier curve, just for completeness, is a parametric curve $B(t)$ outlined by
linearly interpolating between control points with interpolant $t$.
TrueType-fonts (`.ttf`) consists of curves of at most degree 2 (quadratics).
OpenType-fonts (`.otf`) on the other hand can use curves of degree 3 (cubics),
this makes processing them significantly more complicated, but it allows creating
more detailed curves with fewer spline segments.
`.otf`-fonts can be converted to `.ttf` with a tool like FontForge, which allows
us to render any common font while only dealing with the simplest case.

Traditionally, text is rasterized in software into a texture atlas which applications
can sample to render text extremely efficiently after the initial setup.
This is done, essentially, by iterating over $t$-values to rasterize the outline,
and then integrating the resulting texture with a filter to fill the outline and apply
anti-alliasing.
Libraries like FreeType provides this type of rasterization, and provides a lot of
"tricks" to improve the look of the text, such as sub-pixel rendering and font hinting.
(More on this later!)
This works well for programs where the size of a text element is not very dynamic,
or can be known or restricted ahead of time, such as in a web browser or PDF reader,
where the maximal font size can be restricted by restricting the maximal zoom-level.
In order to support arbitrary zoom-level and very dynamic font-sizes, we would either need
to rasterize _massively_ upscaled textures, and downsample _a lot_ in most cases, or
accept pixelated or blurry fonts on large zoom levels. Both solutions are either
extremely inefficient or yield unacceptable quality.

There are hacks that can give you sharp edges, such as textures with distance functions instead
of raw pixel data, which a shader can interpolate to provide a crisp edge, but these techniques
suffer from graphical artifacts, where especially sharp pieces of fonts will disappear.
In general, such techniques tend to "smooth out" the glyphs.
This is obviously unacceptable but especially so in the context of mathematics where symbols
tend to have very long and sharp serifs.

_Real_ hardware font rendering essentially amounts to calculating the winding number of
a fragment with respect to a glyphs outline.
That sounds complicated, mostly because it is.
GPUs are not designed to do this.
But there are some theorems about curves and winding numbers that help us do it
pretty well.
The theory is, again, outlined in more detail in the diary (with examples and problems).

## Winding number in fragment shader
The first approach generaly utilizes the fact that a the winding number
of a fragment can be calculated by counting the intersections of the spline
with a ray eminating from the point in any direction.
I will not attempt prove this, but the result is useful because finding the
intersections of the spline with a ray amounts to solving a quadratic or a
cubic equation, which have explicit formulas.
The formula for the cubic is quite complicated, and dealing with the
number of ways the three potential roots can be placed with respect to the
ray makes it a lot more feasible to simply deal with quadratics, which means
limiting our font selection to `.ttf` fonts.
In this case, there is an algorithm
[by Eric Lengyel](https://jcgt.org/published/0006/02/02/paper.pdf)
that uses a heuristic approach to classify curves based on which
solutions we need to use, which eliminates all numerical error, and
gives a robust rasterization.
An approach using cubics directly is outlined in the diary, but is essentially 
useless because of numerical error.

Lengyels algorithm has one especially nice property:
In its simplest form, there is only one quad per character.
This means the GPU can clip text outside the viewport very efficiently.
The downside is that the winding number calculations requires solving _a lot_
of polynomials in the fragment shader.
The FontForge-converted version of Computer Modern -- the default \LaTeX\ font --
is only a font of modest complexity, but the $\alpha$-glyph still contains
41 quadratic curves, which means that assuming 16xMSAA we need to solve
almost 700 polynomials _per fragment_.
This is mostly fine, since the number of fragments actually processed is
effectively bounded by the resolution, but still it means that the time to draw
a frame can be drastically impacted by scaling a text element.

Another issue is that the mathematical idea behind the heuristic is covered by
a patent. I am not a lawyer, and I don't know if it is legal for me to host code
on Github with such an algorithm, even if implemented purely based off a mathematical
description (the library implementing the algorithm is proprietary software,
so even if I wanted to, there is no way for me to easily rip it off).

An I'm not particularily interested in finding it out the hard way.

## Winding number by modular arithmetic
There is another extremely beautiful theorem that states, essentially, that
if you extend a closed loop of linear splines of the kind surrounding a glyph
with an auxillary point, and instead of tracing the glyphs outline directly
instead trace the new loop defined by visiting this auxillay point between
line segments, the winding number $w'$ of a point with respect to this new curve
is the same as the winding number $w$ with respect to the initial curve modulo 2:
\begin{equation}
w = w' \pmod 2
\end{equation}
Okay, that sounds a bit far out there.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.625\columnwidth]{report/wallace_1.png}
\end{center}
\caption{The contours of $\alpha$ via an auxillary point drawn with transparency and blending
to demonstrate how the winding numbers add up modulo two.}
\label{fig:winding}
\end{figure}
Essentially, what we are stating, is that
drawing over a triangle outlined by a line segment and our auxillary point is the same
as adding +1 to the winding numbers of the fragments in the region.
If we repeat that for every line segment in the contour,
every fragment _inside_ the glyph will have been drawn to $1, 3, 5, \dots$ times.
Every fragment _outside_ the glyph will have been drawn to $0, 2, 4, \dots$ times.

In other words, _modulo two_, fragments inside the glyph will have winding number
$w = 1$, and fragments outside the glyph will have winding number $w = 0$.
If you look closely at Figure \ref{fig:winding}, you can see how this works.
The trick then, is how do we encode this modular arithmetic in draw calls and framebuffers?
This is the core idea behind Evan Wallace's algorithm, described in
[this article on Medium from 2016](https://medium.com/@evanwallace/easy-scalable-text-rendering-on-the-gpu-c3f4d782c5ac).
Wallace encodes this number in a color channel by drawing with intensity \sfrac{1}{255},
and then says:
\begin{displayquote}
The resulting pixel only lies inside the outline if the accumulated color scaled back up by 255 is odd
\end{displayquote}
Now, clearly this has problems (as Wallace himself describes) in the sense that there is a
limit on how many times an outline can overlap itself.
In practice, this isn't much of a problem of course, but its an ugly wart on an otherwise beautiful
method.
Wallace mentions flipping the stencil buffer instead, and this is how similar
techniques have been described in the litterature in the past
[](http://www.glprogramming.com/red/chapter14.html#name13).
This would solve this problem, but is quite a lot of work to do so:
Clearing the stencil buffer, enabling and disabling stencil testing, rendering
a quad to cover it afterwards, and so on.
And if we do this, we still haven't thought about anti-aliasing.
But it turns out there is an easy way to do this,
and as far as i know, this is my original idea, although it is such a trivial
extension of Wallaces idea that it barely counts as an idea.

We don't _have to_ add up all the draw calls and calculate $w \pmod 2$ in the end.
We can simply do all the arithmetic modulo two from the get-go.
How do we do this?
By exploting the fact that addition in the additive group $G = (\{0, 1\}, +)$ has the same
addition table as the truth table for logical XOR.
That's just what people on the top floor of the ivory tower say to say that $1 + 1 = 0$.

By enabling `gl::COLOR_LOGIC_OP`, with the operator `gl::XOR`, we can rasterize the interior
of a glyph by just drawing triangles.
This saves us a lot of "fuckery" (I believe this is the technical term) with the OpenGL state.

\begin{figure*}
\begin{center}
\includegraphics[height=0.2\textwidth]{report/xor_fill.png}
\includegraphics[height=0.2\textwidth]{report/blinn_regions.png}
\includegraphics[height=0.2\textwidth]{report/xor_outline.png}
\end{center}
\caption{The process of applying the outline to a filled glyph.}
\label{fig:outline}
\end{figure*}

As we can see in Figure \ref{fig:outline}, this works great, but we are not done.
What remains is filling the area between the outline and the filled glyph.
To do this, we can use a simple method outlined by
[Loop and Blinn in 2005](https://www.microsoft.com/en-us/research/wp-content/uploads/2005/01/p1000-loop.pdf).
I don't feel like going into detail is necessary:
It is pretty obvious how this works from the paper, so suffice to say that
because Bézier curves are defined by linear interpolation,
linear transformations on the control points will correctly apply to the
curve itself, and thus it is sufficient to solve what is "inside" the Bézier
curve in canonical texture space, and it automatically applies to any triangle
equipped with texture coordinates.

What do we do with this area?
Well, as you can see, some areas, where the boundary extends past the fill (blue highlights),
we need to _fill more fragments_.
In other areas, where the boundary extends inside the filled area (orange highlight), we need to
_take away_.
Filled regions need to be cleared, and empty regions need to be filled.
In other words, it is just one more XOR.
Okay that works great! But there are two minor awkward issues remaining,
both of which thankfully has the same simple solution.

The XOR color logic applies bitwise to the colors present in the framebuffer.
This means it works perfectly well when we are starting with a buffer of all zeros,
and drawing all ones, in other words white on black.
However, if we draw with different colors, the resulting glyph will be shaded with
the bitwise difference between the source color and the destination color.
That's a bit odd.

We have also still not accounted for the need for anti-aliased text.
Wallace accomplishes this by drawing the same text multiple times, slightly offset,
and accumulating 6xMSAA samples in other color channels. Again, this is very clever,
but doing multiple draw calls (for example 16x) with the text means the vertices 
that are not on screen has to be discarded over and over and over (16 times).
This is clearly a big waste.

My solution is to rasterize the text to a separate texture first.
In theory we can use a multisampled texture, but support for and implementation of
these (as i discovered the hard way) vary wildly across platforms, so we won't get 
consistent results.
A more robust approach is to use a normal texture, and rasterize at 16x resolution
and sample a $4 \times 4$ area of 16 texels in the fragment shader.
Taking the roundabout via a separate texture with only one color channel allows us
to clear it to $\alpha = 0$ before we start, and rasterize with $\alpha = 1$,
and then essentially blit this texture to the on-screen framebuffer, thus also
fixing the XOR-related color madness.
Using such a large texture might be prone to hardware limitation on older hardware,
but the integrated graphics on my Ryzen processor allows me to allocate and use a
$16\mathrm K \times 16\mathrm K$ texture without any fuss or apparent performance problems,
so I will not worry about it prematurely.

\begin{table}[h]
\begin{center}
\begin{tabular}{ccc}
\hline
\hline
\scshape 1 Sample & \scshape 4x MS & \scshape 16x MS \\
\hline
\includegraphics[width=.25\columnwidth]{report/aa_test/big_1.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/big_4.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/big_16.png} \\

\includegraphics[width=.25\columnwidth]{report/aa_test/medium_1.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/medium_4.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/medium_16.png} \\

\includegraphics[width=.25\columnwidth]{report/aa_test/tiny_1.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/tiny_4.png} & 
\includegraphics[width=.25\columnwidth]{report/aa_test/tiny_16.png} \\
\hline
\end{tabular}
\end{center}
\caption{Various levels of anti-aliasing, for various font-sizes.}
\label{tab:msaa}
\end{table}

The algorithm provides pretty good-looking anti-aliased glyphs.
We are effectively doing the exact same computation as an algorithm
based on winding-numbers in the fragment shader would do;
we should have the exact same winding numbers for the corresponding samples.
We are just skipping a lot of polynomial-solving to get there.
Table \ref{tab:msaa} shows a breakdown of sample numbers and font sizes.

This algorithm has one big advantage over Lengyels algorithm:
The fragment shader is insanely cheap; it literally just sets the output to 1.
Thus, this method scales better as font sizes increase, which is a good characteristic
in the context of animations and interactive visualizations.
The cost of this is that we are sending _a lot_ more vertices.
When rendering a large volume of text naïvely, almost all the GPUs juice is spent
processing vertices just to discard them, and there is no way around this except
for doing some simple clipping in software so we don't submit too many glyphs that will
get clipped.

All in all, for the workloads we would expect to see in presentations and mathematical
visualizations, we generally see improved performance.

And finally, this algorithm is unpatentable since it would trivially be
invalidated by prior art. Moreover, the algorithm was initially published
under GPL, although it was implemented in a funky language that I have never
heard about, so my implementation is based only on Wallace's mathematical
description, which should not even infringe on copyright,
so I'm free to release it MIT-licensed, which means I can use it at work
without having to open-source the companys data processing system. `:v)`

## Hinting and subixel rendering
A final point about font rasterization quality.
I briefly mentioned earlier that FreeType does hinting and sub-pixel rendering.
Hinting essentially boils down to _adjusting_ the bezier curves surrounding the
glyph to align with the pixel grid. This gives small font sizes crisper edges, but _changes the shape_ of the font.
For this reason it is slightly controversial, between people favoring clear edges, and people favoring representing
a rasterized glyph as the best possible approximation of what the type designer intended.
On modern, high-resolution displays -- generally speaking -- hinting does next to nothing.
If a character is big enough to be legible, even thin bits will contain several sample points, and thus aligning
the curves to the sample points is pointless. I will not attempt to implement hinting.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.625\columnwidth]{report/aa_test/evince_tiny.png}
\end{center}
\caption{Hinted font rasterization in Evince, a popular PDF reader.}
\label{fig:evince}
\end{figure}

For the record, Figure \ref{fig:evince} shows how the same text as in Table \ref{tab:msaa},
with a similar small font size, renders in Evince,
a pretty standard PDF-reader that presumably uses FreeType. As you can see, there is probably
some hinting going on, as the top of the $\nabla$ is quite sharp, and the bottom of the
$\alpha$ is oddly straight. This is because it has been "massaged" into the pixel grid,
thus deforming the glyph in favor of sharpness.
Do note how much more closely the non-hinted version of $\alpha$ resembles the original design of the glyph!
All in all, I don't think I'm doing so bad in comparison to FreeType.

Subpixel rendering would be a nice goal, but since it relies on basically exploiting the physical layout of
a pixel on the screen, and _coloring_ a pixel to light up a speficif fraction of it, this introduces assumptions
about the users monitor. Personally, I have one monitor which is rotated vertically, and one which is not,
so subpixel rendering _just doesnt work_. If i moved a window between monitors, the text would look horrible.
Furthermore, this is just not necessary on modern high resolution displays.

# Typesetting
- horizontal and vertical stacking
- composing symbols made up of separate characters
- deliberately woefully inadequate
- not worth spending time on. want to use a proper tex parser.

# Geometrical primitives
- Lines and linear splines
- Béziers and parametric curves in general
    - tesselation into linear spline
- Circles and circle arcs

# Future work
- wgpu, vulkan, webGL. safe gpu abstraction.
- 
